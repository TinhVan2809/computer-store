# src/chatbot.py
from dotenv import load_dotenv
import os
from openai import RateLimitError
load_dotenv()
# print("DEBUG: API Key Loaded from .env ->", os.getenv("OPENAI_API_KEY"))


from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOllama

from rag_chain import chain
from web_search import search_web

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

db = FAISS.load_local("vector_db", embeddings, allow_dangerous_deserialization=True)

def answer_question(question: str):
    docs = db.similarity_search(question, k=3)

    # N·∫øu FAISS c√≥ d·ªØ li·ªáu
    if docs and docs[0].page_content.strip():
        context = "\n".join([d.page_content for d in docs])
        source = "üìö N·ªôi b·ªô"
    else:
        context = search_web(question)
        source = "üåê Internet"

    answer = chain.run(
        context=context,
        question=question
    )

    return answer, source


if __name__ == "__main__":
    print("ü§ñ Chatbot (g√µ 'exit' ƒë·ªÉ tho√°t)\n")

    while True:
        q = input("üë§ B·∫°n: ")
        if q.lower() == "exit":
            break

        ans, src = answer_question(q)
        print(f"\nü§ñ AI ({src}): {ans}\n")